{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8zktLFOKvF2"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1764631176619,
     "user": {
      "displayName": "Eleanor vander molen",
      "userId": "07508310444067106972"
     },
     "user_tz": 300
    },
    "id": "pf-yWyEgKz3k",
    "outputId": "2dc0fc72-4700-4318-a195-46af6c453235"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Akm08wr4LUYy"
   },
   "source": [
    "# Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1764631181517,
     "user": {
      "displayName": "Eleanor vander molen",
      "userId": "07508310444067106972"
     },
     "user_tz": 300
    },
    "id": "W5hSRTThLWx4",
    "outputId": "043999f5-48eb-4eb3-cf66-98eb17bfb2c9"
   },
   "outputs": [],
   "source": [
    "csv_file_path = 'cleaned_golf_rolling_averages.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "\n",
    "\n",
    "# drop columns we definitely don't need\n",
    "cols_to_drop= [\"bet_type\", \"tie_rule\", \"open_time\", \"close_time\",\n",
    "              \"p1_outcome_text\", \"p2_outcome_text\", \"p3_outcome_text\",\n",
    "              \"book\", \"event_completed\", \"event_name\", \"odds\",\n",
    "\n",
    "             'p1_player_name', 'p2_player_name', 'p3_player_name',\n",
    "\n",
    "             'dg_id_p1', 'fin_text_p1', 'fin_text_p2', 'fin_text_p3',\n",
    "             'course_name_p1', 'teetime_p2', 'teetime_p3', 'wx_teetime',\n",
    "             'wx_datetime_hour',\n",
    "             'wx_date_from_close', 'wx_conditions', 'wx_icon', 'wx_datetimeEpoch',\n",
    "             'tour_p1', 'season']\n",
    "\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "# rename columns we'd like to keep\n",
    "df = df.rename(columns={'teetime_p1':'teetime'})\n",
    "if 'teetime' in df.columns:\n",
    "    df = df.drop(columns=['teetime'])\n",
    "\n",
    "\n",
    "\n",
    "# preciptype can either only be nan or 'rain'\n",
    "if 'wx_preciptype' in df.columns:\n",
    "    df['wx_preciptype'] = df['wx_preciptype'].fillna(0)\n",
    "    df['wx_preciptype'] = df['wx_preciptype'].apply(lambda x: 1 if x != 0 else x)\n",
    "\n",
    "\n",
    "\n",
    "# Create one outcome column\n",
    "if 'outcome' not in df.columns:\n",
    "    raise ValueError(\"DataFrame must not already have an 'outcome' column\")\n",
    "\n",
    "X = df.select_dtypes(include=[\"number\"]).drop(columns=[\"outcome\"])\n",
    "y = df[\"outcome\"]\n",
    "\n",
    "# drop any rows where the target is NaN\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Trainâ€“test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=0,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# impute NaNs in features with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp  = imputer.transform(X_test)\n",
    "\n",
    "#scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_test_scaled  = scaler.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3Uml26XL9g-"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4153,
     "status": "ok",
     "timestamp": 1764631189164,
     "user": {
      "displayName": "Eleanor vander molen",
      "userId": "07508310444067106972"
     },
     "user_tz": 300
    },
    "id": "JuePM0igMBdx",
    "outputId": "d3f07556-14c5-45fc-e09c-cb78aacccb4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eleanor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression accuracy: 0.5032179833970711\n",
      "\n",
      "Confusion matrix:\n",
      "[[3421 1381  204]\n",
      " [2597 1762  184]\n",
      " [ 518  442  212]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.52      0.68      0.59      5006\n",
      "         2.0       0.49      0.39      0.43      4543\n",
      "         3.0       0.35      0.18      0.24      1172\n",
      "\n",
      "    accuracy                           0.50     10721\n",
      "   macro avg       0.46      0.42      0.42     10721\n",
      "weighted avg       0.49      0.50      0.49     10721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "acc = log_reg.score(X_test_scaled, y_test)\n",
    "print(\"\\nLogistic regression accuracy:\", acc)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONVLAH5Qm/PawrylwbcssS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
